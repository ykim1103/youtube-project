{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # 웹 페이지 소스를 얻기 위한 패키지(기본 내장 패키지이다.)\n",
    "from bs4 import BeautifulSoup # 웹 페이지 소스를 얻기 위한 패키지, 더 간단히 얻을 수 있다는 장점이 있다고 한다.\n",
    "from datetime import datetime                                # (!pip install beautifulsoup4 으로 다운받을 수 있다.)\n",
    "import pandas as pd # 데이터를 처리하기 위한 가장 기본적인 패키지\n",
    "import time # 사이트를 불러올 때, 작업 지연시간을 지정해주기 위한 패키지이다. (사이트가 늦게 켜지면 에러가 발생하기 때문)\n",
    "import urllib.request #\n",
    "from selenium.webdriver import Chrome\n",
    "import json\n",
    "import re\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import datetime as dt\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유튜브 채널 이름을 입력해주세요 : 떵개떵\n"
     ]
    }
   ],
   "source": [
    "# 유튜버마다 바꿔줘야 함\n",
    "start_url = 'https://www.youtube.com/channel/UC-i2ywiuvjvpTy2zW-tXfkw/videos'\n",
    "youtube_name = input(\"유튜브 채널 이름을 입력해주세요 : \")\n",
    "delay=4\n",
    "browser = Chrome()\n",
    "browser.implicitly_wait(delay)\n",
    "delay=4\n",
    "browser.get(start_url)\n",
    "browser.maximize_window()\n",
    "\n",
    "#동영상 클릭\n",
    "browser.find_element_by_xpath('//*[@id=\"tabsContent\"]/paper-tab[2]').click()\n",
    "\n",
    "body = browser.find_element_by_tag_name('body')#스크롤하기 위해 소스 추출\n",
    "\n",
    "num_of_pagedowns = 1\n",
    "##10번 밑으로 내리는 것\n",
    "while num_of_pagedowns:\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(2)\n",
    "    num_of_pagedowns -= 1\n",
    "\n",
    "html0 = browser.page_source\n",
    "html = BeautifulSoup(html0,'html.parser')\n",
    "\n",
    "video_list0 = html.find('div',{'id':'items', 'class':'style-scope ytd-grid-renderer'})\n",
    "video_list2 = video_list0.find_all('ytd-grid-video-renderer',{'class':'style-scope ytd-grid-renderer'})\n",
    "\n",
    "base_url = 'http://www.youtube.com'\n",
    "\n",
    "# 영상별 url 구하기\n",
    "\n",
    "video_url = []\n",
    "for i in range(len(video_list2)):\n",
    "    url = base_url+video_list2[i].find('a',{'id':'thumbnail'})['href']\n",
    "    video_url.append(url)\n",
    "\n",
    "\n",
    "video_pd = pd.DataFrame({'name': [],\n",
    "                         'thumbnail': [],\n",
    "                         'view': [],\n",
    "                         'previous_time': [],\n",
    "                         'video_url': [],\n",
    "                         'start_date': [],\n",
    "                         'comment': [],\n",
    "                         'likes_num': [],\n",
    "                         'unlikes_num': [],\n",
    "                         'time_duration': []})\n",
    "base_url = 'http://www.youtube.com'\n",
    "delay = 3\n",
    "browser = Chrome()\n",
    "browser.implicitly_wait(delay)\n",
    "browser.maximize_window()\n",
    "\n",
    "for i in range(0, 20):\n",
    "    name = video_list2[i].find('a', {'id': 'video-title'}).text\n",
    "\n",
    "    thum = video_list2[i].find('a', {'id': 'thumbnail'}).find('img')['src']\n",
    "\n",
    "    url = base_url + video_list2[i].find('a', {'id': 'thumbnail'})['href']\n",
    "\n",
    "    meta0 = video_list2[i].find('div', {'id': 'metadata-line'})\n",
    "\n",
    "    view = meta0.find_all('span', {'class': 'style-scope ytd-grid-video-renderer'})[0].text.split()[1]\n",
    "    # 조회수는 숫자만 뽑을 수 있고 모든 데이터는 원하는 형식으로 뽑을 수 있음\n",
    "    previous = meta0.find_all('span', {'class': 'style-scope ytd-grid-video-renderer'})[1].text\n",
    "    start_date = html.find('div', {'id': 'date'}).find('yt-formatted-string').text\n",
    "    time_duration = video_list2[i].find('span', {'class': 'ytd-thumbnail-overlay-time-status-renderer'}).text\n",
    "\n",
    "    start_url = video_url[i]\n",
    "    browser.get(start_url)\n",
    "    body = browser.find_element_by_tag_name('body')\n",
    "\n",
    "    time.sleep(1.5)  # 브라우저 로딩시간기다려야함\n",
    "\n",
    "    num_of_pagedowns = 1  # page_down은 2로 놔도 괜찮을 듯 최대화 했으므로\n",
    "    while num_of_pagedowns:\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(1.5)  # 스크롤 속도를 지정할 수 있는 것인데  1.5초가 가장 적당할 듯 1초면 너무 빠름\n",
    "        # 현재는 스크롤을 7번만 하도록 설정되어 있으나 이후에 댓글을 크롤링하기 위해서는 스크롤을 댓글이 안보\n",
    "        # 일때까지 내리면 될텐데 시간이 엄청 오래 걸릴 것임 - 따라서 적당한 수준의 댓글을 크롤링하는것이 좋음\n",
    "        num_of_pagedowns -= 1\n",
    "\n",
    "    # 여기에 time.sleep를 집어 넣는 방법을 고안\n",
    "    html0 = browser.page_source\n",
    "    html = BeautifulSoup(html0, 'html.parser')\n",
    "\n",
    "    # 자꾸 오류나서 주석처리 ㅠㅠ\n",
    "    # 댓글 인기순/작성순 선택할 수 있는 영역 클릭\n",
    "    #     browser.find_element_by_xpath('//paper-button[@class=\"dropdown-trigger style-scope yt-dropdown-menu\"]').click()\n",
    "\n",
    "    # 댓글 인기순 카테고리 클릭\n",
    "    #     browser.find_element_by_xpath('//paper-listbox[@class=\"dropdown-content style-scope yt-dropdown-menu\"]/a[1]').click()\n",
    "\n",
    "    comment = html.find('h2', {'id': 'count'}).find('yt-formatted-string').text\n",
    "\n",
    "    # 좋아요수\n",
    "    likes_num = html.find('yt-formatted-string',\n",
    "                          {'id': 'text', 'class': 'style-scope ytd-toggle-button-renderer style-text',\n",
    "                           'aria-label': re.compile('좋아요')}).text + '개'\n",
    "\n",
    "    # 싫어요수\n",
    "    unlikes_num = html.find('yt-formatted-string',\n",
    "                            {'id': 'text', 'class': 'style-scope ytd-toggle-button-renderer style-text',\n",
    "                             'aria-label': re.compile('싫어요')}).text + '개'\n",
    "\n",
    "    insert_data = pd.DataFrame({'name': [name],\n",
    "                                'thumbnail': [thum],\n",
    "                                'view': [view],\n",
    "                                'previous_time': [previous],\n",
    "                                'video_url': [url],\n",
    "                                'start_date': [start_date],\n",
    "                                'comment': [comment],\n",
    "                                'likes_num': [likes_num],\n",
    "                                'unlikes_num': [unlikes_num],\n",
    "                                'time_duration': [time_duration]})\n",
    "\n",
    "    video_pd = video_pd.append(insert_data)\n",
    "\n",
    "    num_page_down = 30\n",
    "    while num_page_down:\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(1.5)\n",
    "        num_page_down -= 1\n",
    "\n",
    "    comment_pd = pd.DataFrame({'youtube_id': [],\n",
    "                               'comment': [],\n",
    "                               'like_num': []})\n",
    "\n",
    "    html_s0 = browser.page_source\n",
    "    html_s = BeautifulSoup(html_s0, 'html.parser')\n",
    "\n",
    "    comment0 = html_s.find_all('ytd-comment-renderer', {'class': 'style-scope ytd-comment-thread-renderer'})\n",
    "\n",
    "    for j in range(len(comment0)):\n",
    "        # 댓글\n",
    "        comment = comment0[j].find('yt-formatted-string',\n",
    "                                   {'id': 'content-text', 'class': 'style-scope ytd-comment-renderer'}).text\n",
    "\n",
    "        try:\n",
    "            aa = comment0[j].find('span', {'id': 'vote-count-left'}).text\n",
    "            # 정규표현식으로 숫자만 추출하는 것은 정규표현식에 대한 공부를 더 한 뒤 해결\n",
    "            # re.findall('[0-9]',aa)\n",
    "            # \"\".join(re.findall('[0-9]',aa)) -> 리스트 내부의 문자열의 합\n",
    "            like_num = \"\".join(re.findall('[0-9]', aa)) + \"개\"\n",
    "        except:\n",
    "            like_num = 0\n",
    "\n",
    "        bb = comment0[j].find('a', {'id': 'author-text'}).find('span').text\n",
    "        youtube_id = \"\".join(re.findall('[가-힣0-9a-zA-Z]', bb))\n",
    "\n",
    "        insert_data = pd.DataFrame({'youtube_id': [youtube_id],\n",
    "                                    'comment': [comment],\n",
    "                                    'like_num': [like_num]})\n",
    "\n",
    "        comment_pd = comment_pd.append(insert_data)\n",
    "        comment_pd.index = range(len(comment_pd))\n",
    "\n",
    "    if not os.path.exists(f'{youtube_name}/comment'):\n",
    "        os.makedirs(f'{youtube_name}/comment')\n",
    "    comment_pd.to_csv(f\"{youtube_name}/comment/{youtube_name}_comment_{i + 1}.csv\", mode='w', encoding='utf-8-sig')\n",
    "\n",
    "video_pd.index = range(len(video_pd))\n",
    "if not os.path.exists(f'{youtube_name}'):\n",
    "    os.makedirs(f'{youtube_name}')\n",
    "video_pd.to_csv(f\"{youtube_name}/{youtube_name}_info.csv\", mode='w', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
